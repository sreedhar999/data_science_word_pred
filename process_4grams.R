
### This R script processes chunks of a text corpus iteratively

### into a data.table that contains these variables:

### V1 - V4: char: 4-gram separated accross 4 columns.

### twit, news, blog: int: frequency of each 4-gram in each source.

### Source: factor (t, n, b): source identifier.

### (optionally) Total: int: total frequency of 4-gram



### Libraries

rm(list=ls(all.names = T))  ## clear the environment

library(stylo)

library(data.table)

library(Revobase)



### Setup

setMKLthreads(16)

getMKLthreads()

setwd("~/en_USx/")

options(stringsAsFactors = FALSE) ## for readline()

docs<-list.files(getwd())

n <- 4  ## ngram

tot.freqs <- data.table(ngrams=character(0),twit=integer(0),
                        
                        blog=integer(0),news=integer(0))



### Preprocess the data chunks

##### Sizes: Each chunk has 20k lines.

#####        Twitter chunks are 14 MB Blogs and News are 16 MB.

#####        The entire corpus is 557 MB.

##### Remove unwanted characters, i.e. non-printable, numbers, emoticons.

##### We'd like to keep apostrophes for now.

##### Apostrophes form contractions and the genitive (possessive) case.

##### We also want to keep carriage returns to keep the lines separated.

##### We're going lowercase.

######## Let's try with 47 MB of data.

system.time(
  
  for(i in docs){
    
    apostrophe<-paste0("sed \"y/â€™/'/\" < ",i," > ",i,".apo")
    
    system(apostrophe)
    
    ### For OS X, use "sed -E" instead of "sed -r":
    
    dothis<-paste0("sed -r \"s/[^[:alpha:] \\r\\n']/ /g\" < ", i,".apo > ",i,".dot")
    
    system(dothis)
    
    tolower <- paste0("tr \"[:upper:]\" \"[:lower:]\" < ", i,".dot > ",i,".tol")
    
    system(tolower)
    
    rewrite_og <- paste0("mv ",i,".tol ",i)
    
    system(rewrite_og)
    
    system("rm *.apo")
    
    system("rm *.dot")
    
  }
  
)



### FUNCTION: Use `stylo` to make 4-grams.

##### Returns a character list of 4-gram strings.

to_ngrams <- function(textchunk,n){
  
  require(stylo)
  
  gramn <- unlist( lapply( textchunk[grep(
    
    "[^ ]*[aeiouyAEIOUY]+[^ ]* [^ ]*[aeiouyAEIOUY]+[^ ]* [^ ]*[aeiouyAEIOUY]+[^ ]* [^ ]*[aeiouyAEIOUY]+[^ ]*", textchunk)],
    
    function(store) make.ngrams(txt.to.words(
      
      store, splitting.rule = "[ \t\n]+"), ngram.size = n) ) )
  
  gramn
  
}



### FUNCTION: Sort by frequency.

##### Returns a data.table of 2 variables:

#####   ngrams: char: 4-gram

#####   `sourcename`: int: frequency

#####   `sourcename` can be "twit","news", or "blog")

sort_freqs <- function(ngrams,sourcename){
  
  require(data.table)
  
  freqs <- as.data.table(table(ngrams))
  
  freqs <- freqs[order(-freqs$N),]
  
  ### Change variable N to source ###
  
  setnames(freqs,"N",sourcename)
  
  freqs
  
}



### FUNCTION: Add other sources' columns.

##### Returns a data.table of 4 variables:

#####   ngrams: char: 4-gram

#####   twit, news, blog: int: frequency

add_cols <- function(x.freq){
  
  if(!"twit" %in% names(x.freq))
    
    x.freq[,twit:=0]
  
  if(!"blog" %in% names(x.freq))
    
    x.freq[,blog:=0]
  
  if(!"news" %in% names(x.freq))
    
    x.freq[,news:=0]
  
  x.freq
  
}



### FUNCTION: Accumulate frequency counts.

##### Returns a data.table of 4 variables:

#####   ngrams: char: 4-gram

#####   twit, news, blog: int: frequency

accum_freqs <- function (freqs,new_freqs){
  
  require(data.table)
  
  cf <- rbind(freqs,new_freqs) ## combined freqs
  
  cf <- cf[, lapply(.SD, sum), by = c("ngrams")]
  
  ### See section 2.1 of http://cran.r-project.org/web/packages/data.table/vignettes/datatable-faq.pdf
  
  cf
  
}



### 

system.time(
  
  for(i in docs){    
    
    sourcename<-unlist(strsplit(i, "_"))[2]
    
    text.l <- readLines(i,skipNul = T)
    
    text.n <- to_ngrams(text.l,n)
    
    freq.s <- sort_freqs(text.n,sourcename)
    
    freq.t <- add_cols(freq.s)
    
    tot.freqs <- accum_freqs(tot.freqs,freq.t)
    
  }
  
)



save(tot.freqs, file="tot.freqs.RData")



